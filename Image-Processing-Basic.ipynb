{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full example the includes all python scripts within the repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IF RUNNING IN COLAB, RUN THIS CELL FIRST\n",
    "# Clone the repository so we can access the data\n",
    "!git clone https://github.com/lambjames18/PythonImageProcessing-MaterialsScience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import numpy as np\n",
    "from skimage import io, exposure, filters\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.feature import peak_local_max\n",
    "from scipy import ndimage as ndi\n",
    "import torch\n",
    "from sklearn import preprocessing, decomposition\n",
    "import matplotlib.pyplot as plt\n",
    "# Activate the interactive mode of matplotlib within colab (if we are using colab)\n",
    "try:\n",
    "    from google.colab import output\n",
    "    output.enable_custom_widget_manager()\n",
    "except:\n",
    "    pass\n",
    "# Static plots\n",
    "%matplotlib inline\n",
    "\n",
    "# Set device to the GPU if available\n",
    "# For MacOS, use the Multi-Process Service (MPS) to run on the GPU if available\n",
    "if os.name == \"nt\":\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "elif os.name == \"posix\":\n",
    "    if os.uname().sysname == \"Darwin\":\n",
    "        device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    else:\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(image):\n",
    "    \"\"\"Normalize the image to the range [0, 255] and convert to uint8.\"\"\"\n",
    "    image = image.astype(float)\n",
    "    return np.around(255 * (image - image.min(axis=(0, 1))) / (image.max(axis=(0, 1)) - image.min(axis=(0, 1)))).astype(np.uint8)\n",
    "\n",
    "\n",
    "def un_norm(image):\n",
    "    \"\"\"Rescale the image to the range [0, 1].\"\"\"\n",
    "    image = image.astype(float)\n",
    "    return ((image - image.min(axis=(0, 1))) / (image.max(axis=(0, 1)) - image.min(axis=(0, 1))))\n",
    "\n",
    "\n",
    "# Read in the image\n",
    "im = io.imread(\"./imgs/EBSD-Pattern.tif\").astype(float)\n",
    "\n",
    "# Create a dynamic background (really blurred version of the image) and subtract it from the original image\n",
    "background = filters.gaussian(im, sigma=50)\n",
    "im_new = un_norm(im - background)\n",
    "\n",
    "# Apply contrast limiting adaptive histogram equalization (CLAHE) to the background-removed image\n",
    "im_new_clahe = exposure.equalize_adapthist(im_new, clip_limit=0.01)\n",
    "\n",
    "# Normalize the images and save them\n",
    "im = norm(im)\n",
    "background = norm(background)\n",
    "im_new = norm(im_new)\n",
    "im_new_clahe = norm(im_new_clahe)\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(12, 8), sharex=True, sharey=True)\n",
    "ax[0, 0].imshow(im, cmap=\"gray\")\n",
    "ax[0, 0].set_title(\"Original\")\n",
    "ax[0, 1].imshow(background, cmap=\"gray\")\n",
    "ax[0, 1].set_title(\"Background\")\n",
    "ax[1, 0].imshow(im_new, cmap=\"gray\")\n",
    "ax[1, 0].set_title(\"Background Removed\")\n",
    "ax[1, 1].imshow(im_new_clahe, cmap=\"gray\")\n",
    "ax[1, 1].set_title(\"CLAHE\")\n",
    "for a in ax.ravel():\n",
    "    a.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Principal component analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data file, select ROI (keeping all features), and extract dataset shape and number of features\n",
    "data = np.load(\"./EBSD_data.npy\")\n",
    "\"\"\"\n",
    "Structure of the data: (n_features, n_rows, n_columns)\n",
    "Labels for the feature entries: Euler_1, Euler_2, Euler_3, GROD, IPF001_1, IPF001_2, IPF001_3, IPF100_1, IPF100_2, IPF100_3, MisIPF001_1, MisIPF001_2, MisIPF001_3, MisIPF100_1, MisIPF100_2, MisIPF100_3, KAM, CI, Phase, IQ\n",
    "\"\"\"\n",
    "\n",
    "# Put the features in the last dimension\n",
    "data = np.moveaxis(data, 0, -1)\n",
    "\n",
    "# Get the number of features and the shape of the dataset\n",
    "n_features = data.shape[-1]\n",
    "shape = data.shape\n",
    "\n",
    "# Scale the data and perform PCA\n",
    "data_scaled = preprocessing.StandardScaler().fit_transform(data.reshape(-1, n_features))\n",
    "pca = decomposition.PCA(n_components=n_features)\n",
    "X_pca = pca.fit_transform(data_scaled)\n",
    "X_pca = X_pca.reshape(shape)\n",
    "\n",
    "# Plot the results\n",
    "fig, ax = plt.subplots(2, 3, figsize=(16, 10), sharex=True, sharey=True)\n",
    "ax[0, 0].imshow(X_pca[:, :, 0], cmap=\"gray\")\n",
    "ax[0, 1].imshow(X_pca[:, :, 1], cmap=\"gray\")\n",
    "ax[0, 2].imshow(X_pca[:, :, 2], cmap=\"gray\")\n",
    "ax[1, 0].imshow(data[:, :, 3], cmap=\"gray\")  # GROD\n",
    "ax[1, 1].imshow(data[:, :, -1], cmap=\"gray\")  # CI\n",
    "ax[1, 2].imshow(data[:, :, 4:7].astype(int))  # IPF\n",
    "for a in ax.ravel():\n",
    "    a.axis(\"off\")\n",
    "labels = [\"PCA1\", \"PCA2\", \"PCA3\", \"GROD\", \"CI\", \"IPF\"]\n",
    "for i, a in enumerate(ax.ravel()):\n",
    "    a.text(0.02, 0.98, labels[i], color=\"black\", transform=a.transAxes, fontsize=14, verticalalignment=\"top\", fontweight=\"heavy\", backgroundcolor=\"white\")\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variational autoencoder (VAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Variational autoencoder structure\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "class VEncoder(nn.Module):\n",
    "    def __init__(self, height, width, n_features, latent_size):\n",
    "        super(VEncoder, self).__init__()\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.conv0 = nn.Conv2d(n_features, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv1 = nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.fc_mu = nn.Linear(64 * (self.height // 8) * (self.width // 8), latent_size)\n",
    "        self.fc_logvar = nn.Linear(64 * (self.height // 8) * (self.width // 8), latent_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv0(x))\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        return mu, logvar\n",
    "\n",
    "\n",
    "class VDecoder(nn.Module):\n",
    "    def __init__(self, height, width, n_features, latent_size):\n",
    "        super(VDecoder, self).__init__()\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.fc = nn.Linear(latent_size, 64 * (self.height // 8) * (self.width // 8))\n",
    "        self.deconv0 = nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.deconv1 = nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "        self.deconv2 = nn.ConvTranspose2d(16, n_features, kernel_size=3, stride=2, padding=1, output_padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc(x))\n",
    "        x = x.view(x.size(0), 64, (self.height // 8), (self.width // 8))\n",
    "        x = F.relu(self.deconv0(x))\n",
    "        x = F.relu(self.deconv1(x))\n",
    "        x = self.deconv2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class VAutoencoder(nn.Module):\n",
    "    def __init__(self, height, width, n_features, latent_size, lr=0.001):\n",
    "        super(VAutoencoder, self).__init__()\n",
    "        self.encoder = VEncoder(height, width, n_features, latent_size)\n",
    "        self.decoder = VDecoder(height, width, n_features, latent_size)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encoder(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        x_reconstructed = self.decoder(z)\n",
    "        return x_reconstructed, mu, logvar\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(-1.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def get_latent_vectors(self, x, num_samples=0):\n",
    "        with torch.no_grad():\n",
    "            mu, logvar = self.encoder(x)\n",
    "            latent_vectors = []\n",
    "            for _ in range(num_samples):\n",
    "                z = self.reparameterize(mu, logvar)\n",
    "                latent_vectors.append(z)\n",
    "        return torch.stack(latent_vectors).squeeze(0)\n",
    "\n",
    "    def train(self, input_data, num_epochs):\n",
    "        for epoch in range(num_epochs):\n",
    "            # Forward pass\n",
    "            output_data, mu, logvar = self(input_data)\n",
    "\n",
    "            # Compute the loss, including the KL divergence term\n",
    "            reconstruction_loss = self.criterion(output_data, input_data)\n",
    "            kl_divergence = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "            loss = reconstruction_loss + kl_divergence\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Reconstruction Loss: {reconstruction_loss.item():.4f}, KL Divergence: {kl_divergence.item():.4f}' + \" \" * 10, end=\"\\r\", flush=True)\n",
    "        print(f'Final Loss: {loss.item():.4f}, Final reconstruction Loss: {reconstruction_loss.item():.4f}, KL Divergence: {kl_divergence.item():.4f}' + \" \" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Example usage\n",
    "\n",
    "# Define the latent space size for the VAE\n",
    "latent_size = 20  # Can be tuned\n",
    "\n",
    "# Read in the data file, select ROI (keeping all features), and extract dataset shape and number of features\n",
    "data = np.load(\"./imgs/EBSD_data.npy\")[:, :448, :512]\n",
    "\n",
    "\"\"\"\n",
    "Structure of the data: (n_features, n_rows, n_columns)\n",
    "Features: Euler_1, Euler_2, Euler_3, GROD, IPF001_1, IPF001_2, IPF001_3, IPF100_1, IPF100_2, IPF100_3, MisIPF001_1, MisIPF001_2, MisIPF001_3, MisIPF100_1, MisIPF100_2, MisIPF100_3, KAM, CI, Phase, IQ\n",
    "\"\"\"\n",
    "\n",
    "# Put the features in the last dimension\n",
    "data = np.moveaxis(data, 0, -1)\n",
    "\n",
    "height, width, n_features = data.shape\n",
    "batch_size = 1 # Because we are using a single image\n",
    "\n",
    "# Preprocess data to be between 0 and 1 and have a mean of 0 and standard deviation of 1\n",
    "input_data = (data - data.min(axis=(1, 2))[:, None, None]) / (data.max(axis=(1, 2)) - data.min(axis=(1, 2)))[:, None, None]\n",
    "input_data = (input_data - input_data.mean(axis=(1, 2))[:, None, None]) / input_data.std(axis=(1, 2))[:, None, None]\n",
    "input_data = torch.from_numpy(input_data).float().unsqueeze(0).to(device)\n",
    "# For VAE, the input data should be in the shape (Batches, Channels, Height, Width)\n",
    "input_data = torch.moveaxis(input_data, -1, 1)\n",
    "\n",
    "# Example usage:\n",
    "vae = VAutoencoder(input_data.shape[2], input_data.shape[3], n_features, latent_size).to(device)\n",
    "vae.train(input_data, 100)\n",
    "\n",
    "# Sample a few latent space vectors (analogous to PCA vectors)\n",
    "vae_data = vae.get_latent_vectors(input_data, num_samples=3).cpu().numpy()\n",
    "vae_data = np.squeeze(vae_data)\n",
    "\n",
    "# Process the results into images\n",
    "new_data = data.dot(vae_data.T)\n",
    "grod = data[:, :, 3]\n",
    "ci = data[:, :, -1]\n",
    "ipf = data[:, :, 4:7].astype(int)\n",
    "\n",
    "# Visualize\n",
    "fig, ax = plt.subplots(2, 3, figsize=(16, 10), sharex=True, sharey=True)\n",
    "ax[0, 0].imshow(new_data[:, :, 0], cmap=\"gray\")\n",
    "ax[0, 1].imshow(new_data[:, :, 1], cmap=\"gray\")\n",
    "ax[0, 2].imshow(new_data[:, :, 2], cmap=\"gray\")\n",
    "ax[1, 0].imshow(grod, cmap=\"gray\")\n",
    "ax[1, 1].imshow(ci, cmap=\"gray\")\n",
    "ax[1, 2].imshow(ipf)\n",
    "for a in ax.ravel():\n",
    "    a.axis(\"off\")\n",
    "labels = [\"VAE1\", \"VAE2\", \"VAE3\", \"GROD\", \"CI\", \"IPF\"]\n",
    "for i, a in enumerate(ax.ravel()):\n",
    "    a.text(0.02, 0.98, labels[i], color=\"black\", transform=a.transAxes, fontsize=14, verticalalignment=\"top\", fontname=\"Avenir\", fontweight=\"heavy\", backgroundcolor=\"white\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Watershed segmentation + SNOW algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SNOW algorithm\n",
    "r'''\n",
    "SNOW: Sub-Network of an Oversegmented Watershed\n",
    "Copyright (C) 2017 Jeff Gostick\n",
    "\n",
    "This program is free software: you can redistribute it and/or modify\n",
    "it under the terms of the GNU General Public License as published by\n",
    "the Free Software Foundation, either version 3 of the License, or\n",
    "(at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful,\n",
    "but WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the\n",
    "GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License\n",
    "along with this program.  If not, see <http://www.gnu.org/licenses/>.\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.ndimage as spim\n",
    "import scipy.spatial as sptl\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import feature, segmentation\n",
    "\n",
    "\n",
    "def trim_nearby_peaks(peaks, dt):\n",
    "    \"\"\"Function to remove peaks that are too close to each other in the distance map\"\"\"\n",
    "    if dt.ndim == 2:\n",
    "        from skimage.morphology import square as cube\n",
    "    else:\n",
    "        from skimage.morphology import cube\n",
    "    peaks, N = spim.label(peaks, structure=cube(3))\n",
    "    crds = spim.center_of_mass(peaks, labels=peaks, index=np.arange(1, N+1))\n",
    "    crds = np.vstack(crds).astype(int)  # Convert to numpy array of ints\n",
    "    # Get distance between each peak as a distance map\n",
    "    tree = sptl.cKDTree(data=crds)\n",
    "    temp = tree.query(x=crds, k=2)\n",
    "    nearest_neighbor = temp[1][:, 1]\n",
    "    dist_to_neighbor = temp[0][:, 1]\n",
    "    del temp, tree  # Free-up memory\n",
    "    dist_to_solid = dt[list(crds.T)]  # Get distance to solid for each peak\n",
    "    dist_to_solid = dt[tuple(crds.T)]\n",
    "    hits = np.where(dist_to_neighbor < dist_to_solid)[0]\n",
    "    # Drop peak that is closer to the solid than its neighbor\n",
    "    drop_peaks = []\n",
    "    for peak in hits:\n",
    "        if dist_to_solid[peak] < dist_to_solid[nearest_neighbor[peak]]:\n",
    "            drop_peaks.append(peak)\n",
    "        else:\n",
    "            drop_peaks.append(nearest_neighbor[peak])\n",
    "    drop_peaks = np.unique(drop_peaks)\n",
    "    # Remove peaks from image\n",
    "    slices = spim.find_objects(input=peaks)\n",
    "    for s in drop_peaks:\n",
    "        peaks[slices[s]] = 0\n",
    "    return (peaks > 0)\n",
    "\n",
    "\n",
    "def extend_slice(s, shape, pad=1):\n",
    "    \"\"\"Function to pad a slice by a given amount\"\"\"\n",
    "    a = []\n",
    "    for i, dim in zip(s, shape):\n",
    "        start = 0\n",
    "        stop = dim\n",
    "        if i.start - pad >= 0:\n",
    "            start = i.start - pad\n",
    "        if i.stop + pad < dim:\n",
    "            stop = i.stop + pad\n",
    "        a.append(slice(start, stop, None))\n",
    "    return tuple(a)\n",
    "\n",
    "\n",
    "def trim_saddle_points(peaks, dt, max_iters=10):\n",
    "    \"\"\"Function to remove saddle points from the peaks\"\"\"\n",
    "    if dt.ndim == 2:\n",
    "        from skimage.morphology import square as cube\n",
    "    else:\n",
    "        from skimage.morphology import cube\n",
    "    labels, N = spim.label(peaks)\n",
    "    slices = spim.find_objects(labels)\n",
    "    for i in range(N):\n",
    "        s = extend_slice(s=slices[i], shape=peaks.shape, pad=10)\n",
    "        peaks_i = labels[s] == i + 1\n",
    "        dt_i = dt[s]\n",
    "        im_i = dt_i > 0\n",
    "        iters = 0\n",
    "        peaks_dil = peaks_i.copy()\n",
    "\n",
    "        while iters < max_iters:\n",
    "            iters += 1\n",
    "            peaks_dil = spim.binary_dilation(input=peaks_dil,\n",
    "                                             structure=cube(3))\n",
    "            peaks_max = peaks_dil*np.amax(dt_i*peaks_dil)\n",
    "            peaks_extended = (peaks_max == dt_i)*im_i\n",
    "            if np.all(peaks_extended == peaks_i):\n",
    "                break  # Found a true peak\n",
    "            elif np.sum(peaks_extended*peaks_i) == 0:\n",
    "                peaks_i = False\n",
    "                break  # Found a saddle point\n",
    "            peaks[s] = peaks_i\n",
    "    return peaks\n",
    "\n",
    "\n",
    "def snow(im, sigma, r_max):\n",
    "    \"\"\"Function to perform the SNOW algorithm on an image\"\"\"\n",
    "    dt = spim.distance_transform_edt(input=im)\n",
    "    dt = spim.gaussian_filter(input=dt, sigma=sigma)\n",
    "    peaks_locs = feature.peak_local_max(image=dt, min_distance=r_max-1, exclude_border=0) #, indices=False)\n",
    "    peaks = np.zeros(shape=dt.shape, dtype=bool)\n",
    "    peaks[tuple(peaks_locs.T)] = True\n",
    "    peaks = trim_saddle_points(peaks=peaks, dt=dt)\n",
    "    peaks = trim_nearby_peaks(peaks=peaks, dt=dt)\n",
    "    regions = segmentation.watershed(image=-dt, markers=spim.label(peaks)[0], mask=im)\n",
    "    return regions\n",
    "\n",
    "\n",
    "def create_image(shape, porosity, radius=10):\n",
    "    \"\"\"Function to create a synthetic image with a given porosity\"\"\"\n",
    "    im = np.ones(shape=shape, dtype=bool)\n",
    "    while im.sum()/im.size > porosity:\n",
    "        temp = np.random.rand(*shape) < 0.9999\n",
    "        temp = spim.distance_transform_edt(input=temp) > radius\n",
    "        im *= temp\n",
    "    return np.logical_not(im)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Example usage\n",
    "\n",
    "# Get the image\n",
    "im = io.imread(\"./imgs/WCu-Composite.tiff\")\n",
    "\n",
    "# Create a mask of the tungsten particles\n",
    "tungsten_mask = im > filters.threshold_otsu(im)\n",
    "\n",
    "# Set the minimum distance between seed points\n",
    "min_distance = 50\n",
    "\n",
    "# Calculate the distance to the nearest zero pixel for each pixel of the image\n",
    "distance = ndi.distance_transform_edt(tungsten_mask)\n",
    "# Find the peaks in the distance map\n",
    "coords = peak_local_max(distance, footprint=np.ones((3, 3)), labels=tungsten_mask, min_distance=20)\n",
    "# Create the markers for the watershed algorithm\n",
    "mask = np.zeros(distance.shape, dtype=bool)\n",
    "mask[tuple(coords.T)] = True\n",
    "# Label the seed points as markers for the watershed algorithm\n",
    "markers, _ = ndi.label(mask)\n",
    "# Perform the watershed algorithm\n",
    "labels = watershed(-distance, markers, mask=tungsten_mask)\n",
    "\n",
    "### Now we will use the SNOW algorithm to segment the image\n",
    "sigma = 0.1\n",
    "r_max = 5\n",
    "labels_snow = snow(im=tungsten_mask, sigma=sigma, r_max=r_max)\n",
    "\n",
    "# Randomize the labels to make the plot look better, do this for both the original and SNOW labels\n",
    "def shuffle_labels(labels, seed=0):\n",
    "    unique_ids = np.unique(labels)[1:]  # Remove 0 because its the background\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(unique_ids)\n",
    "    unique_ids = np.concatenate(([0], unique_ids))  # Add 0 back to the beginning\n",
    "    shuffled_labels = np.zeros_like(labels)\n",
    "    for i, unique_id in enumerate(unique_ids):\n",
    "        shuffled_labels[labels == unique_id] = i\n",
    "    return shuffled_labels\n",
    "\n",
    "shuffled_labels = shuffle_labels(labels)\n",
    "shuffled_labels_snow = shuffle_labels(labels_snow)\n",
    "\n",
    "# Plot the results\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 6), sharex=True, sharey=True)\n",
    "ax[0].imshow(im, cmap=plt.cm.gray)\n",
    "ax[0].set_title('Overlapping objects')\n",
    "ax[0].axis('off')\n",
    "ax[1].imshow(shuffled_labels, cmap=plt.cm.nipy_spectral)\n",
    "ax[1].set_title('Separated objects')\n",
    "ax[1].axis('off')\n",
    "ax[2].imshow(shuffled_labels_snow, cmap=plt.cm.nipy_spectral)\n",
    "ax[2].set_title('Separated objects (SNOW)')\n",
    "ax[2].axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the image\n",
    "image = io.imread(\"./imgs/CeO2.tiff\", as_gray=True)\n",
    "background = io.imread(\"./imgs/CeO2_Background.tiff\", as_gray=True)\n",
    "\n",
    "image = image - background  # Remove the background\n",
    "image = image[:, :image.shape[0]]  # Crop the image to make it square\n",
    "image = (image - image.min()) / (image.max() - image.min())  # Normalize the image within the range [0, 1]\n",
    "\n",
    "# Rotate image\n",
    "rot_image = np.rot90(image, 1)\n",
    "\n",
    "# Intensity adjustment\n",
    "adj_image = exposure.adjust_gamma(image, 0.5)\n",
    "\n",
    "# Sharpen image\n",
    "sharpened_image = filters.unsharp_mask(image, radius=1, amount=10)\n",
    "\n",
    "# Create synthetic data\n",
    "input_data = (image - image.mean()) / image.std()\n",
    "input_data = torch.from_numpy(input_data).float().unsqueeze(0).unsqueeze(0).to(device)\n",
    "vae = VAE.VAutoencoder(input_data.shape[2], input_data.shape[3], 1, 10).to(device)\n",
    "vae.train(input_data, 1000)\n",
    "vae_image = vae(input_data)[0].detach().squeeze().cpu().numpy()\n",
    "\n",
    "# Export the images\n",
    "image = np.around(255 * (image - image.min()) / (image.max() - image.min())).astype(np.uint8)\n",
    "rot_image = np.around(255 * (rot_image - rot_image.min()) / (rot_image.max() - rot_image.min())).astype(np.uint8)\n",
    "adj_image = np.around(255 * (adj_image - adj_image.min()) / (adj_image.max() - adj_image.min())).astype(np.uint8)\n",
    "sharpened_image = np.around(255 * (sharpened_image - sharpened_image.min()) / (sharpened_image.max() - sharpened_image.min())).astype(np.uint8)\n",
    "vae_image = np.around(255 * (vae_image - vae_image.min()) / (vae_image.max() - vae_image.min())).astype(np.uint8)\n",
    "\n",
    "fig, ax = plt.subplots(2, 3, figsize=(12, 8))\n",
    "ax[0, 0].imshow(image, cmap=\"gray\")\n",
    "ax[0, 0].set_title(\"Original\")\n",
    "ax[0, 1].imshow(rot_image, cmap=\"gray\")\n",
    "ax[0, 1].set_title(\"Rotated\")\n",
    "ax[0, 2].imshow(adj_image, cmap=\"gray\")\n",
    "ax[0, 2].set_title(\"Adjusted\")\n",
    "ax[1, 0].imshow(sharpened_image, cmap=\"gray\")\n",
    "ax[1, 0].set_title(\"Sharpened\")\n",
    "ax[1, 1].imshow(vae_image, cmap=\"gray\")\n",
    "ax[1, 1].set_title(\"VAE\")\n",
    "for a in ax.ravel():\n",
    "    a.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stitching",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
